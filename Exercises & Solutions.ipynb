{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "+ Compute an approximation $\\pi$ using Monte Carlo. \n",
    "\n",
    "How?  If we can estimate the area of the unit circle, then dividing by $r^2 = (1/2)^2 = 1/4$\n",
    "gives an estimate of $\\pi$. We may estimate the area by sampling bivariate uniforms and looking at the fraction that fall into the unit circle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## My solution.\n",
    "\n",
    "from math import sqrt\n",
    "import random \n",
    "n = 1000000\n",
    "\n",
    "count = 0\n",
    "for i in range(n):\n",
    "    u, v = random.random(), random.random()\n",
    "    d = sqrt((u - 0.5)**2 + (v - 0.5)**2)\n",
    "    if d < 0.5:\n",
    "        count += 1.0\n",
    "\n",
    "area_estimate = count / n\n",
    "\n",
    "print(area_estimate * 4)  # dividing by radius**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "+ Write a function with two parameters <code>a</code> and <code>b</code>, to compute the final amount we get if we deposite 1000€ during <code>a</code> years in a bank account with an interest rate of <code>b</code> per cent.\n",
    "+ What is the result for ``a``=10, ``b``=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "+ Write a function with one parameter <code>a</code>, to compute the minimum period we need to double the amount in an account with an interest rate of <code>a</code> per cent.\n",
    "+ What is the result for ``a``=3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "> (...) In mathematics, the sieve of Eratosthenes, one of a number of prime number sieves, is a simple, ancient algorithm for finding all prime numbers up to any given limit. A prime number is a natural number which has exactly two distinct natural number divisors: 1 and itself. To find all the prime numbers less than or equal to a given integer $n$ by Eratosthenes' method.\n",
    "> (Source: *Wikipedia*)\n",
    "\n",
    "+ Write a program to implement the Eratostenes algorithm. First create a list of consecutive integers from 2 through $n$: (2, 3, 4, ..., n). Then,    \n",
    "    - Initially, let $p$ equal 2, the first prime number.\n",
    "    - Starting from $p$, enumerate its multiples by counting to $n$ in increments of $p$, and mark them in the list (these will be 2p, 3p, 4p, etc.; the $p$ itself should not be marked).\n",
    "    - Find the first number greater than $p$ in the list that is not marked. If there was no such number, stop. Otherwise, let $p$ now equal this new number (which is the next prime), and repeat from step 2.\n",
    "    - When the algorithm terminates, all the numbers in the list that are not marked are prime. (...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sieve(n):\n",
    "    \"Return all primes <= n.\"\n",
    "    np1 = n + 1\n",
    "    s = range(np1) \n",
    "    s[1] = 0\n",
    "    sqrtn = int(round(n**0.5))\n",
    "    for i in xrange(2, sqrtn + 1): \n",
    "        if s[i]:\n",
    "            s[i*i: np1: i] = [0] * len(xrange(i*i, np1, i))\n",
    "    return filter(None, s)\n",
    "\n",
    "%timeit sieve(1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise  \n",
    "\n",
    "+ Compute the set of bigrams of a string. (``'hola'->'ho'+'ol'+'la'``) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = \"mariposa salvaje\"\n",
    "bigrams = [a[i:i+2] for i in range(len(a)-1)]\n",
    "print bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "+ Compute the set of substrings of a string.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a=\"hola\"\n",
    "cont=0\n",
    "for j in range(len(a)):\n",
    "    for i in range(j+1,len(a)+1):\n",
    "        cont=cont+1\n",
    "        print cont,(a[j:i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** \n",
    "\n",
    "+ Take two lists, say for example these two:\n",
    "\n",
    "\t``a = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]  b = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]``\n",
    "    \n",
    "  and write a program that returns a list that contains only the elements that are common between the lists (without duplicates)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = [1, 1, 2, 3, 5, 8, 13, 21, 34, 55, 89]\n",
    "b = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]\n",
    "result = [i for i in set(a) if i in b]\n",
    "print result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Build a simple class called ``Polynomia``l for representing and manipulating polynomial functions such as\n",
    "\n",
    "$$ p(x) = a_0 + a_1 x + \\dots + a_n x^n $$\n",
    "\n",
    "The instance data for the class ``Polynomial`` will be the coefficients ($a_1, \\dots, a_n$). Provide methods that:\n",
    "\n",
    "+ Evaluate the polynomial, returning $p(x)$ for any $x$\n",
    "+ Differentiate the polynomial, replacing the original coefficients with those of its derivative $p′$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Polynomial(object):\n",
    "\n",
    "    def __init__(self, coefficients):\n",
    "        \"\"\"\n",
    "        Creates an instance of the Polynomial class representing \n",
    "            p(x) = a_0 x^0 + ... + a_N x^N,           \n",
    "        where a_i = coefficients[i].\n",
    "        \"\"\"\n",
    "        self.coefficients = coefficients\n",
    "\n",
    "    def eval(self, x):\n",
    "        \"Evaluate the polynomial at x.\"\n",
    "        y = 0\n",
    "        for i, a in enumerate(self.coefficients):\n",
    "            y += a * x**i  \n",
    "        return y\n",
    "\n",
    "    def differentiate(self):\n",
    "        \"Reset self.coefficients to those of p' instead of p.\"\n",
    "        new_coefficients = []\n",
    "        for i, a in enumerate(self.coefficients):\n",
    "            new_coefficients.append(i * a)\n",
    "        # Remove the first element, which is zero\n",
    "        del new_coefficients[0]  \n",
    "        # And reset coefficients data to new values\n",
    "        self.coefficients = new_coefficients\n",
    "        \n",
    "a = Polynomial([2,4])\n",
    "print a.eval(1)\n",
    "a.differentiate()\n",
    "print a.eval(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Consider the polynomial\n",
    "\n",
    "$$ p(x) = a_0 + a_1 x + \\dots + a_n x^n $$\n",
    "\n",
    "Write a function ``p`` such that ``p(x, coeff)`` computes the value in the polynomial given a point ``x`` and a list of coefficients ``coeff``. Try to use ``enumerate()`` in your loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p(x, coeff):\n",
    "    return sum(a * x**i for i, a in enumerate(coeff))\n",
    "\n",
    "p(1, (2, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "1. Determine the maximum of a list of numerical values by using ``reduce``.\n",
    "2. Calculate the sum of the numbers from 1 to 100 by using ``reduce``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = lambda a,b: a if (a > b) else b\n",
    "print reduce(f, [47,11,42,102,13])\n",
    "\n",
    "print reduce(lambda x, y: x+y, range(1,101))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "By using a grid representation:\n",
    "+ Build a graphical representation of all multiples of 3 numbers from 0 to 49 by using exclusively the ``slicing`` operator (no iterations). ``BlockGrid(50, 1, block_size=10, fill=(123, 234, 123))``\n",
    "+ Build a graphical representation of the prime numbers from 0 to 4999. (Hint: Compute the list of prime numbers and map this list to the grid representation). ``BlockGrid(50, 100, block_size=10, fill=(123, 234, 123))``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Rewrite the following functions so that it is fully vectorized: that is, so that it consists of a sequence of NumPy operations on whole arrays, with no native Python loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%timeit np.sum(np.arange(3000)) * np.sum(np.arange(3000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%timeit np.sum(np.searchsorted(np.sort(np.arange(0, 200, 2)), np.arange(40, 140)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise \n",
    "\n",
    "In the following table we have expression values for 5 genes at 4 time points. \n",
    "\n",
    "                        Gene name   4h\t12h\t  24h\t48h\n",
    "                        A2M        0.12\t0.08  0.06\t0.02\n",
    "                        FOS        0.01\t0.07  0.11\t0.09\n",
    "                        BRCA2      0.03\t0.04  0.04\t0.02\n",
    "                        CPOX       0.05\t0.09  0.11\t0.14\n",
    "\n",
    "+ Create a single array for the data (4x4)\n",
    "+ Find the mean expression value per gene\n",
    "+ Find the mean expression value per time point\n",
    "+ Which gene has the maximum mean expression value? (Use the ``tab`` help on an array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Consider the polynomial\n",
    "\n",
    "$$ p(x) = a_0 + a_1 x + \\dots + a_n x^n $$\n",
    "\n",
    "Earlier, you wrote a simple function ``p(x, coeff)`` to evaluate it without considering efficiency. \n",
    "\n",
    "Now write a new function that does the same job, but uses NumPy arrays and array operations for its computations, rather than any form of Python loop.\n",
    "\n",
    "Hint: Use ``np.cumprod()``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def p(x, coef):\n",
    "    X = np.empty(len(coef))\n",
    "    X[0] = 1\n",
    "    X[1:] = x\n",
    "    y = np.cumprod(X)   # y = [1, x, x**2,...]\n",
    "    res = np.sum(coef * y)\n",
    "    return res\n",
    "\n",
    "coef = np.random.rand(1,3000000)\n",
    "print(p(1, coef))\n",
    "\n",
    "%timeit p(1, coef)\n",
    "\n",
    "def p(x, coeff):\n",
    "    return sum(a * x**i for i, a in enumerate(coeff))\n",
    "\n",
    "%timeit p(1, coef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "+ Read the titanic dataset from ``files/titanic.xls`` and inspect the first records.\n",
    "+ Are there columns have NaN values? \n",
    "+ Drop those rows with NaN values in ``age``. \n",
    "+ What was the probability of survival? Get a variable with this value.\n",
    "+ What was the probability of survival for each ``pclass``? Get a varible with this value.\n",
    "+ What was the mean age for third class survivors? Get a variable with this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "titanic_data = pd.read_excel(\"files/titanic.xls\")\n",
    "titanic_data.head( 3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "titanic_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned = titanic_data.dropna(subset = ['age'])\n",
    "df_cleaned.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_survived = df_cleaned['survived'].mean() \n",
    "print p_survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned.groupby('pclass')['survived'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_cleaned[(df_cleaned['pclass']==3) & (df_cleaned['survived']==1)]['age'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Movielens 1M database (http://www.grouplens.org/node/73) stores 1,000,209 scorings from 3.900 films that were compiled in 2000 from 6.040 anonymou users of the online MovieLens recommender (http://www.movielens.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "unames = ['user_id', 'gender', 'age', 'occupation', 'zip']\n",
    "users = pd.read_table('files/ml-1m/users.dat', sep='::', header=None, names=unames, engine='python')\n",
    "rnames = ['user_id', 'movie_id', 'rating', 'timestamp']\n",
    "ratings = pd.read_table('files/ml-1m/ratings.dat', sep='::', header=None, names=rnames, engine='python')\n",
    "mnames = ['movie_id', 'title', 'genres']\n",
    "movies = pd.read_table('files/ml-1m/movies.dat', sep='::', header=None, names=mnames, engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "mean_ratings = data.groupby(by='user_id')['rating'].mean()\n",
    "mean_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "movies_by_user = data.pivot(index='movie_id', columns='user_id', values='rating')\n",
    "\n",
    "def top_movie(dataFrame,usr):\n",
    "    return dataFrame[usr].argmax()\n",
    "\n",
    "print top_movie(movies_by_user, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def assign_to_set(df):\n",
    "    sampled_ids = np.random.choice(df.index,\n",
    "                                   size=np.int64(np.ceil(df.index.size * 0.2)),\n",
    "                                   replace=False)\n",
    "    df.ix[sampled_ids, 'for_testing'] = True\n",
    "    return df\n",
    "data = pd.merge(pd.merge(ratings, users), movies)\n",
    "data['for_testing'] = False\n",
    "grouped = data.groupby('user_id', group_keys=False).apply(assign_to_set)\n",
    "movielens_train = data[grouped.for_testing == False]\n",
    "movielens_test = data[grouped.for_testing == True]\n",
    "print movielens_train.shape\n",
    "print movielens_test.shape\n",
    "\n",
    "def compute_rmse(y_pred, y_true):\n",
    "    return np.sqrt(np.mean(np.power(y_pred - y_true, 2)))\n",
    "\n",
    "def evaluate(estimate,test=movielens_test):\n",
    "    ids_to_estimate = zip(test['user_id'], test['movie_id'])\n",
    "    estimated = np.array([estimate(u,i) for (u,i) in ids_to_estimate])\n",
    "    real = test.rating.values\n",
    "    return compute_rmse(estimated, real)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pivoted_movielens_train = movielens_train.pivot(index='movie_id', columns='user_id', values='rating')\n",
    "mean_movielens_train = pivoted_movielens_train.mean()\n",
    "\n",
    "def rec2(user_id, item_id,train=mean_movielens_train):\n",
    "    return train[user_id]\n",
    "\n",
    "print 'Error: %s' % evaluate(rec2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm  \n",
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "df = pd.read_csv('files/portland-oregon-average-monthly-.csv', index_col=0)\n",
    "df.index.name=None\n",
    "df.reset_index(inplace=True)\n",
    "df.drop(df.index[114], inplace=True)\n",
    "start = datetime.datetime.strptime(\"1973-01-01\", \"%Y-%m-%d\")\n",
    "date_list = [start + relativedelta(months=x) for x in range(0,114)]\n",
    "df['index'] =date_list\n",
    "df.set_index(['index'], inplace=True)\n",
    "df.index.name=None\n",
    "df.columns= ['riders']\n",
    "df['riders'] = df.riders.apply(lambda x: int(x)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.riders.plot(figsize=(12,8), title= 'Monthly Ridership', fontsize=14)\n",
    "plt.savefig('month_ridership.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "decomposition = seasonal_decompose(df.riders, freq=12)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  \n",
    "fig.set_size_inches(15, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller\n",
    "def test_stationarity(timeseries):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.rolling_mean(timeseries, window=12)\n",
    "    rolstd = pd.rolling_std(timeseries, window=12)\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    orig = plt.plot(timeseries, color='blue',label='Original')\n",
    "    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show()\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print 'Results of Dickey-Fuller Test:'\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    print dfoutput\n",
    "    \n",
    "test_stationarity(df.riders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.riders_log= df.riders.apply(lambda x: np.log(x))  \n",
    "test_stationarity(df.riders_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['first_difference'] = df.riders - df.riders.shift(1)  \n",
    "test_stationarity(df.first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['log_first_difference'] = df.riders_log - df.riders_log.shift(1)  \n",
    "test_stationarity(df.log_first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['seasonal_difference'] = df.riders - df.riders.shift(12)  \n",
    "test_stationarity(df.seasonal_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['log_seasonal_difference'] = df.riders_log - df.riders_log.shift(12)  \n",
    "test_stationarity(df.log_seasonal_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['seasonal_first_difference'] = df.first_difference - df.first_difference.shift(12)  \n",
    "test_stationarity(df.seasonal_first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['log_seasonal_first_difference'] = df.log_first_difference - df.log_first_difference.shift(12)  \n",
    "test_stationarity(df.log_seasonal_first_difference.dropna(inplace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "import matplotlib.pyplot as plt  \n",
    "import statsmodels.api as sm  \n",
    "import seaborn as sb  \n",
    "sb.set_style('darkgrid')\n",
    "\n",
    "path = 'files/stock_data.csv'  \n",
    "stock_data = pd.read_csv(path)  \n",
    "stock_data['Date'] = stock_data['Date'].convert_objects(convert_dates='coerce') \n",
    "stock_data = stock_data.sort_values(by='Date')  \n",
    "stock_data = stock_data.set_index('Date')  \n",
    "\n",
    "stock_data['Close'].plot(figsize=(12, 4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_data['First Difference'] = stock_data['Close'] - stock_data['Close'].shift()  \n",
    "\n",
    "stock_data['First Difference'].plot(figsize=(12, 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_data['Natural Log'] = stock_data['Close'].apply(lambda x: np.log(x))  \n",
    "stock_data['Natural Log'].plot(figsize=(12, 4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_data['Original Variance'] = stock_data['Close'].rolling(window=30,center=True).var()  \n",
    "stock_data['Log Variance'] = stock_data['Natural Log'].rolling(window=30,center=True).var()\n",
    "\n",
    "fig, ax = plt.subplots(2, 1, figsize=(12, 4))  \n",
    "stock_data['Original Variance'].plot(ax=ax[0], title='Original Variance')  \n",
    "stock_data['Log Variance'].plot(ax=ax[1], title='Log Variance')  \n",
    "fig.tight_layout()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_data['Logged First Difference'] = stock_data['Natural Log'] - stock_data['Natural Log'].shift()  \n",
    "stock_data['Logged First Difference'].plot(figsize=(12, 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stock_data['Lag 1'] = stock_data['Logged First Difference'].shift()  \n",
    "stock_data['Lag 2'] = stock_data['Logged First Difference'].shift(2)  \n",
    "stock_data['Lag 5'] = stock_data['Logged First Difference'].shift(5)  \n",
    "stock_data['Lag 30'] = stock_data['Logged First Difference'].shift(30)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sb.jointplot('Logged First Difference', 'Lag 1', stock_data, kind='reg', size=8) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import acf  \n",
    "from statsmodels.tsa.stattools import pacf\n",
    "\n",
    "lag_correlations = acf(stock_data['Logged First Difference'].iloc[1:])  \n",
    "lag_partial_correlations = pacf(stock_data['Logged First Difference'].iloc[1:]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,4))  \n",
    "ax.plot(lag_correlations, marker='o', linestyle='--')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "decomposition = seasonal_decompose(stock_data['Natural Log'], model='additive', freq=30)  \n",
    "fig = plt.figure()  \n",
    "fig = decomposition.plot()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(stock_data['Natural Log'].iloc[1:], order=(1, 0, 0))  \n",
    "results = model.fit(disp=-1)  \n",
    "stock_data['Forecast'] = results.fittedvalues  \n",
    "stock_data[['Natural Log', 'Forecast']].plot(figsize=(12,4))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(stock_data['Logged First Difference'].iloc[1:], order=(1, 0, 0))  \n",
    "results = model.fit(disp=-1)  \n",
    "stock_data['Forecast'] = results.fittedvalues  \n",
    "stock_data[['Logged First Difference', 'Forecast']].plot(figsize=(12,4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stock_data[['Logged First Difference', 'Forecast']].iloc[1200:1600, :].plot(figsize=(12, 4))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = sm.tsa.ARIMA(stock_data['Logged First Difference'].iloc[1:], order=(0, 0, 1))  \n",
    "results = model.fit(disp=-1)  \n",
    "stock_data['Forecast'] = results.fittedvalues  \n",
    "stock_data[['Logged First Difference', 'Forecast']].plot(figsize=(12,4)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "Anomaly Detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context=\"notebook\", style=\"white\", palette=sns.color_palette(\"RdBu\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mat = pd.read_csv('files/ex8data1.csv')\n",
    "X = np.array(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6,4))  \n",
    "plt.scatter(X[:,0], X[:,1], c='b', marker='x')\n",
    "plt.title(\"Outlier detection\")\n",
    "plt.xlabel('Latency (ms)')\n",
    "plt.ylabel('Throughput (mb/s)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mu = X.mean(axis=0)\n",
    "print mu, '\\n'\n",
    "\n",
    "cov = np.cov(X.T)\n",
    "print cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create multi-var Gaussian model\n",
    "multi_normal = stats.multivariate_normal(mu, cov)\n",
    "\n",
    "# create a grid\n",
    "x, y = np.mgrid[0:30:0.01, 0:30:0.01]\n",
    "pos = np.dstack((x, y))\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# plot probability density\n",
    "ax.contourf(x, y, multi_normal.pdf(pos), cmap='Blues')\n",
    "\n",
    "# plot original data points\n",
    "sns.regplot('Latency', 'Throughput',\n",
    "           data=pd.DataFrame(X, columns=['Latency', 'Throughput']), \n",
    "           fit_reg=False,\n",
    "           ax=ax,\n",
    "           scatter_kws={\"s\":10,\n",
    "                        \"alpha\":0.4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def estimate_gaussian(X):  \n",
    "    mu = X.mean(axis=0)\n",
    "    sigma = X.var(axis=0)\n",
    "\n",
    "    return mu, sigma\n",
    "\n",
    "mu, sigma = estimate_gaussian(X)  \n",
    "mu, sigma  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p = np.zeros((X.shape[0], X.shape[1]))  \n",
    "p[:,0] = stats.norm(mu[0], sigma[0]).pdf(X[:,0])  \n",
    "p[:,1] = stats.norm(mu[1], sigma[1]).pdf(X[:,1])\n",
    "\n",
    "outliers = np.where(p < 0.009)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,4))  \n",
    "ax.scatter(X[:,0], X[:,1])  \n",
    "ax.scatter(X[outliers[0],0], X[outliers[0],1], s=50, color='r', marker='o') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sig2 = np.linspace(0, 5, num=30)\n",
    "sig2 = np.concatenate([sig2 for x in xrange(12)])\n",
    "\n",
    "# Add a jump\n",
    "jump_size = 5\n",
    "sig2[250:] = sig2[250:] + jump_size\n",
    "\n",
    "# Noise\n",
    "noise = np.random.normal(\n",
    "    size=sig2.shape,\n",
    "    scale=jump_size * 0.1)\n",
    "\n",
    "ser = pd.Series(sig2) + noise\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(ser, 'b.', alpha=0.5)\n",
    "plt.ylim(0,15)\n",
    "plt.xlim(0,365)\n",
    "plt.title(\"sig2 : A non-trivial signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ser_diff = ser - ser.shift(30)  \n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(ser_diff, 'b.', alpha=0.5)\n",
    "plt.ylim(0,15)\n",
    "plt.xlim(0,365)\n",
    "plt.title(\"sig2 : A non-trivial signal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mean1 = ser_diff.rolling(window=3,center=False).mean()\n",
    "mean2 = ser_diff.rolling(window=20,center=False).mean()\n",
    "mean_dif = abs(mean1 - mean2)\n",
    "change = mean_dif.argmax()\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(ser_diff, 'b.', alpha=0.5)\n",
    "plt.axvline(x=change, ymin=0, ymax = 100, linewidth=2, color='k')\n",
    "plt.ylim(0,15)\n",
    "plt.xlim(0,365)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
